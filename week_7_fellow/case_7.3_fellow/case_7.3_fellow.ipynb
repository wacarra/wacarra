{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can I experiment with online travel deals to attract more customers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import IFrame\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "## Case Introduction\n",
    "\n",
    "**Business Context.** Your company TravelSmart is a growing company and is competing with a few big players in the market. As part of a marketing promotion to increase the user base, you have decided to give an extra 5% discount for users who book both flights and hotels at TravelSmart.com, rather than flight tickets alone.\n",
    "     \n",
    "**Business Problem.** The company would like you to answer the following question: **\"Should we be offering this 5% bundle discount promotion if our goal is to increase our purchasing customer count?\"**\n",
    "\n",
    "**Analytical Context.** The scenario above can be viewed as an **A/B test**. A/B testing is a way of determining whether a potential change (\"Version B\", as opposed to the existing \"Version A\") improves key business metrics, like sales or conversions.\n",
    "\n",
    "<img src=\"A-B.png\"\n",
    "     alt=\"Markdown Monster icon\"\n",
    "     style=\"float: left; margin-right: 10px;\" />\n",
    "     \n",
    "The case is structured as follows: you will (1) define and state a precise hypothesis; (2) deploy the A/B test; (3) analyze the results of the test; and finally (4) systematically decide the next steps of whether you should go and implement a change or stay with the current version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "2_min"
    ]
   },
   "source": [
    "## Designing the experiment: developing a concise hypothesis\n",
    "\n",
    "Spaghetti is delicious, but even more delicious when the pasta is cooked just right. Many chefs use the “spaghetti test” – throw spaghetti at the wall and if it sticks, it’s cooked. This is a great example of poor hypothesis design because it doesn’t give any indication of when or why the spaghetti should be considered done.\n",
    "\n",
    "Like cooking spaghetti, before proceeding with any experiment or test (in this case, an A/B test), we need to define a very precise hypothesis so that we have a context on which to evaluate the results of our experiment or test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "### Exercise 1\n",
    "\n",
    "Suppose we wanted to move forward with the proposed 5% deal mentioned above. Which of the following hypotheses are you testing with your experiment?\n",
    "\n",
    "<ul>\n",
    "A. The 5% discount for users booking both flights and hotels will ultimately increase revenue.<br>\n",
    "B. The 5% discount will bring in more online subscriptions to our site.<br>\n",
    "C. The 5% discount will incentivize users who book flights to also book hotels.<br>\n",
    "D. The 5% discount allows for TravelSmart to increase base prices of hotels without affecting sales numbers, so the net revenue balances out but users are more satisfied by purchasing with a discount.<br>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "7_min"
    ]
   },
   "source": [
    "## Identifying control variables\n",
    "\n",
    "Now that we have a concise hypothesis, we should think about what might go wrong and how we can prevent or mitigate potential issues. One major aspect to consider is **control variables**. Control variables are quantifiable elements that remain unchanged throughout an experiment. Identifying your control variables is very important for mitigating noisy data because slight variations in variables which you expect to remain constant throughout your experiment can greatly affect the outcomes being measured, in ways that have nothing to do with what you are specifically interested in testing. \n",
    "\n",
    "For example, say Taylor regularly takes a walk with his dog every morning. He decides to go on a diet and increases vegetable consumption for the next few weeks. Taylor wants to learn whether this will lead to weight loss. Over the next few weeks, Taylor feels that he is lacking the energy to get up early in the morning and often ends up not going for a walk. Taylor ends up gaining a few pounds. \n",
    "\n",
    "This is an example of a poorly designed experiment. The few extra pounds could have been due to a number of things *other than his diet*, including lack of exercise. Thus it is not possible to learn if vegetable consumption contributed to weight loss from this experiment. If Taylor identified daily exercise to be a control variable, this experiment would have been a lot more successful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "### Exercise 2\n",
    "\n",
    "Let's identify the potential control variables we need to consider in our experiment. Which of the following variables do you think are significant enough to control for? Select all that apply.\n",
    "\n",
    "<ul>\n",
    "A. Changes to the user experience and visuals on the website that were already previously scheduled to deploy.<br>\n",
    "B. Existence of a brand new, unique route that no other competitor offers.<br>\n",
    "C. Performance of your sales team.<br>\n",
    "D. Updates to the current engineering infrastructure of the website.<br>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control variables are extremely hard to get an exhaustive list of, but that’s okay. In the real world, there are a lot of variables that affect people's behavior that are simply unavoidable. Choice C above is a perfect example of this. This does not mean such variables should be neglected, but they don't have to be strictly controlled; they merely need to be accounted for to a reasonable extent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "12_min"
    ]
   },
   "source": [
    "## Defining KPIs\n",
    "\n",
    "Once we have identified the relevant hypothesis and variables, we are nearly ready to deploy our experiment. The last thing to consider is choosing what variable(s) we should be measuring so that evaluating the outcome of this experiment is very clear. These variables are called **Key Performance Indicators (KPIs)**. There are a lot of different metrics that we can consider, but all of them can be classified as either micro or macro conversions.\n",
    "\n",
    "**Macro conversions** are the *ideal* metrics that are directly tied with our business objective. In this case, macro conversions refer to the customer-accretive metrics of the website. **Micro conversions** are metrics that may be indicative of, but do not guarantee, progress towards those macro conversions. The table below are a few examples of macro and micro conversions for TravelSmart:\n",
    "\n",
    "| Macro Conversions            | Micro Conversions           |\n",
    "| ---------------------------- | --------------------------- |\n",
    "| Total Number of Ticket Sales | Views on a Specific Route   |\n",
    "| Membership Purchases         | Time Spent on Landing Page  |\n",
    "| Sales and Leads Conversions  | Number of Referral Accounts |\n",
    "\n",
    "Let’s do the following experiment to better understand macro and micro conversions. Suppose your ran your deal for 60 days, and on Day 60 and we arrived at some data given in the following plot:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "<img src=\"KPI.png\"\n",
    "     alt=\"Markdown Monster icon\"\n",
    "     style=\"float: left; margin-right: 10px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table summarizes the above plot. Let’s analyze what’s going on in this fictitious scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def color_negative_red(value):\n",
    "    if '%' not in str(value):\n",
    "        return ''\n",
    "    value = float(value.rstrip('%'))\n",
    "    if value < 0:\n",
    "        color = '#d65f5f'\n",
    "    elif value > 0:\n",
    "        color = '#5fba7d'\n",
    "    else:\n",
    "        color = 'black'\n",
    "    return 'background-color: %s' % color\n",
    "\n",
    "days = 60\n",
    "df_experiment = pd.read_csv('micro_macro_dataset.csv')\n",
    "pre_experiment = df_experiment.loc[1:days]\n",
    "post_experiment = df_experiment.loc[days+1:2*days]\n",
    "pre_means = pre_experiment.mean().apply(floor)\n",
    "post_means = post_experiment.mean().apply(floor)\n",
    "percentage_changes = ((post_means - pre_means)/pre_means*100).map(\"{:.2f}%\".format)\n",
    "\n",
    "means = pd.DataFrame({\n",
    "    \"Pre-Experiment Mean\": pre_means,\n",
    "    \"Post-Experiment Mean\": post_means,\n",
    "    \"Percentage Changes\" : percentage_changes\n",
    "}).transpose()\n",
    "means.style.applymap(color_negative_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we see that there are more visits to these specific pages, the number of tickets purchased and hotels booked did not change significantly. This reflects poorly on our experiment because it seems like there was no change to ticket sales, but we actually lost money by offering lower ticket and hotel prices. In this case, we say that the macro conversions were unaffected by this experiment and we deem the experiment unsuccessful.\n",
    "\n",
    "Our major takeaway is that whenever we define an experiment, we ideally want to identify and track macro conversions as our KPIs. Micro conversions can be helpful, but the primary focus should be on macro conversions whenever possible. The main reason to track a micro conversion over a macro conversion would be if it is difficult to impossible to actually measure that macro conversion directly, in which case the micro conversion becomes a sort of proxy for progress towards the \"ideal\" macro conversion.\n",
    "\n",
    "For our experiment, the most sensible macro conversion to use is the number of distinct users who purchased a ticket or booked a hotel, because this is directly correlated to our user base count, which is exactly what we are trying to expand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "2_min"
    ]
   },
   "source": [
    "## Treatment and control groups\n",
    "\n",
    "All right, we are now ready to deploy our experiment. As implied in the name of this test, we have to split our user base into two groups, groups A and B. That way, we can apply the experiment on group B and see how it compares with the group with no changes, group A. We refer to group B as the **treatment group** (the \"treatment\" here refers to the deal being offered) and group A as the **control group**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "### Exercise 3\n",
    "\n",
    "Imagine that you have 100,000 users. How would you deploy the experiment?\n",
    "\n",
    "<ul>\n",
    "A. Start out by exposing 2% (2000) of users to the experiment. If the experiment sees no noticeable impact, ramp up the experiment to 50% (50000) users.<br>\n",
    "B. Start out by exposing 2% (2000) users to the experiment. If the experiment sees no noticeable impact, ramp up the experiment to 7% (7000) users, and later on to more and more users.<br>\n",
    "C. Expose 10% (10000) users to the experiment. This is a balanced size of the treatment group; it is just large enough to see the results of the experiment and exposes a small enough population in case the experiment is unsuccessful.<br>\n",
    "D. Give the deal to 50% (50000) users with the intention to compare against the control group. This increases the information gain and increases efficiency.<br>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "### Exercise 4\n",
    "\n",
    "Consider the following 2 options for deploying your experiment:\n",
    "\n",
    "<ul>\n",
    "I. The first 2% of users get the new deal.<br> \n",
    "II. Randomly pick 2% of the users to get the new deal.<br>\n",
    "</ul>\n",
    "\n",
    "Which of the following statements is true?\n",
    "\n",
    "<ul>\n",
    "A. Option I is best, as it is the fastest way to learn about whether users like the deal.<br>\n",
    "B. Option II is better than Option I because you are more likely to get a representative group of users.<br>\n",
    "C. Randomly picking users makes the whole experiment difficult to analyze because we do not have control over who gets the deal, and thus what one learns from this experiment is uncertain.<br>\n",
    "D. Option I and II are not really different unless we have more information<br>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "2_min"
    ]
   },
   "source": [
    "## Exploring randomization\n",
    "\n",
    "Randomly giving 2% of users the deal does not mean that exactly 2% of users at any given time have received the deal. As users come visit your website throughout the day, the actual percentage of users getting the deal fluctuates around 2%, as the following visualization shows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(\"./histogram.html\", height=450, width=\"100%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "### Exercise 5\n",
    "\n",
    "Suppose you ran the experiment for a day, randomly giving the deal to 2% of the users. Suppose also that you have a user base of over one million. However, at the end of the day, you observe that only about 1% of the users actually received the deal. Which of the following choices best explains this discrepancy?\n",
    "\n",
    "<ul>\n",
    "A. 1% is well within the variation you would expect because of the randomization, and thus you can proceed with ramping up the experiment.<br>\n",
    "B. 1% is definitely much lower than what you would expect, even accounting for the variation. Thus you might suspect a bug in your software and consult your engineering team to check if all of the intended users are getting the deal or not.<br>\n",
    "C. Yes, it is outside the range of what you would expect the sample size to be, but you can still proceed with ramping up the experiment because there are still a large number of users who got the deal.<br>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "7_min"
    ]
   },
   "source": [
    "## Ramping up the experiment\n",
    "\n",
    "Now that you have run your experiment for 2% of the user base for a couple of days, it is the time to ramp up your experiment. Before discussing how and when to ramp up, let's first discuss how to understand the results of an A/B experiment.\n",
    "\n",
    "Let's suppose you decide to randomly give the deal to 10% of users and have run it for a couple of days. If you are interested in purchasing users, you may calculate the difference in percentage of purchasing users between the two groups. Suppose we have run the experiment and observed the following outcome for the difference in percentage of purchasing users between group A and group B:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td><b>95% confidence interval</b></td><td>(0.2%, 1.4%)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>$p$ - value for the hypothesis that there is no difference in purchasing users between the two groups </b></td><td>0.004 </td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "The 95% confidence interval indicates that it is 95% likely that the percentage of purchasing users in group B is between 0.2% and 1.4% greater than the percentage of purchasing users in group A. As 0% is outside the interval, we can conclude at the $\\alpha = 0.05$ significance level that the percentage of purchasing users is statistically significantly higher for users who are given the deal. This is also reflected in the $p$ - value of 0.004.\n",
    "\n",
    "If the experiment is run for longer, the confidence interval will be narrower. This is because the number of users given the deal increases with time. This increase in information leads to more precision in our estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "2_min"
    ]
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "In this case, we learned about conducting A/B tests online. You learned about how to properly define a hypothesis, control variables, KPIs, and finally set up and analyze the results of the experiment. We learned in this case that the deal did indeed increase the percentage of purchasing users by almost 1%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "3_min"
    ]
   },
   "source": [
    "## Takeaways\n",
    "\n",
    "A/B tests are a powerful tool to conduct rapid experimentation and quickly learn about the preferences of your users. However, any A/B test you run must ensure proper randomization. It ensures that you will not accidentally exclude any user base and derive conclusions based on a biased sample. With an A/B test, one usually starts the experiment on a small percentage of users so as to mitigate risk. After this initial step, the experiment can be ramped up."
   ]
  }
 ],
 "metadata": {
  "c1_recart": "6.7.0-57c20131aabc1dc2a8c675852d80a7da"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
