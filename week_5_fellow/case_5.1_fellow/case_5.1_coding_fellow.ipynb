{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do we prepare data for a bike share analytics platform?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "6_min"
    ]
   },
   "source": [
    "## Exploring the data\n",
    "\n",
    "Dealing with unclean data is not necessarily glamorous, yet it is always essential. A common example would be a repetitive typo; e.g. 1% of the rows having \"New York\" spelled as \"New Yok\". We can use a combination of `.groupby()` and `.count()` in order to get a summary of the different values in a particular column, and notice that there are some common misspelled proper nouns.\n",
    "\n",
    "It can also be a good habit to shuffle the data and sift through a few hundred/thousand rows manually to get a good \"feel\" for the data. While this may seem excessive, you may catch an insight that would dramatically accelerate your subsequent work. Learn to love manually digging into the data if you want to be a data professional.\n",
    "\n",
    "Let's read the data using the `.read_csv()` method. Note that we are passing a parameter `nrows=10000` so that we only read in the first 10,000 rows in the file (we are working with a subset of the data on our local machine as the entire dataset is quite large - more than 3 million rows):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rental Id</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Bike Id</th>\n",
       "      <th>End Date</th>\n",
       "      <th>EndStation Id</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>StartStation Id</th>\n",
       "      <th>tag</th>\n",
       "      <th>userCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101428476</td>\n",
       "      <td>1680</td>\n",
       "      <td>12829.0</td>\n",
       "      <td>03/09/2020 20:32</td>\n",
       "      <td>132.0</td>\n",
       "      <td>03/09/2020 20:04</td>\n",
       "      <td>574</td>\n",
       "      <td>priority_medium</td>\n",
       "      <td>['A']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101522714</td>\n",
       "      <td>2700</td>\n",
       "      <td>10863.0</td>\n",
       "      <td>06/09/2020 12:56</td>\n",
       "      <td>702.0</td>\n",
       "      <td>06/09/2020 12:11</td>\n",
       "      <td>82</td>\n",
       "      <td>priority Medium</td>\n",
       "      <td>['B']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101377356</td>\n",
       "      <td>420</td>\n",
       "      <td>3997.0</td>\n",
       "      <td>02/09/2020 10:56</td>\n",
       "      <td>97.0</td>\n",
       "      <td>02/09/2020 10:49</td>\n",
       "      <td>225</td>\n",
       "      <td>priority Medium</td>\n",
       "      <td>['A']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101393663</td>\n",
       "      <td>660</td>\n",
       "      <td>16542.0</td>\n",
       "      <td>02/09/2020 18:40</td>\n",
       "      <td>622.0</td>\n",
       "      <td>02/09/2020 18:29</td>\n",
       "      <td>97</td>\n",
       "      <td>priority Medium</td>\n",
       "      <td>['A']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101622659</td>\n",
       "      <td>660</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>08/09/2020 19:57</td>\n",
       "      <td>219.0</td>\n",
       "      <td>08/09/2020 19:46</td>\n",
       "      <td>36</td>\n",
       "      <td>priority_medium</td>\n",
       "      <td>['A']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rental Id  Duration  Bike Id          End Date  EndStation Id  \\\n",
       "0  101428476      1680  12829.0  03/09/2020 20:32          132.0   \n",
       "1  101522714      2700  10863.0  06/09/2020 12:56          702.0   \n",
       "2  101377356       420   3997.0  02/09/2020 10:56           97.0   \n",
       "3  101393663       660  16542.0  02/09/2020 18:40          622.0   \n",
       "4  101622659       660   1605.0  08/09/2020 19:57          219.0   \n",
       "\n",
       "         Start Date  StartStation Id              tag userCategory  \n",
       "0  03/09/2020 20:04              574  priority_medium        ['A']  \n",
       "1  06/09/2020 12:11               82  priority Medium        ['B']  \n",
       "2  02/09/2020 10:49              225  priority Medium        ['A']  \n",
       "3  02/09/2020 18:29               97  priority Medium        ['A']  \n",
       "4  08/09/2020 19:46               36  priority_medium        ['A']  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data file and take a look at the data\n",
    "df = pd.read_csv('data/trips.csv', nrows=10000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed before, the first step we ought to take with a new dataset is to familiarize ourselves with it. Let's read through the columns present in the dataset, find out how the data is spread out across columns, etc. This will also give us a sense of the obvious cleaning steps to be performed on each column present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Rental Id', 'Duration', 'Bike Id', 'End Date', 'EndStation Id',\n",
       "       'Start Date', 'StartStation Id', 'tag', 'userCategory'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of available features is as follows:\n",
    "\n",
    "1. **Rental Id:** A user can purchase the right to pick any bike in the city within 24 hours for Â£2. This column contains the ID of the rental (which may correspond to more than one bike). Notice that this is *not* the ID of the journey. Data type: `int64`.\n",
    "1. **Duration:** The duration of the journey in seconds. Data type: `int64`.\n",
    "2. **Bike Id:** The ID of the bike. Data type: `int64`.\n",
    "3. **End Date:** End time of the journey. Data type: `object`.\n",
    "4. **EndStation Id:** ID of the station at which this journey ended. Data type: `int64`.\n",
    "5. **Start Date:** Start time of the journey. Data type: `object`.\n",
    "6. **StartStation Id:** ID of the station at which this journey started. Data type: `int64`.\n",
    "7. **tag:** A tag that one of the members of your team assigned to each journey to make it easier to group them for further analysis. This column was not part of the original dataset. Data type: `object`.\n",
    "8. **userCategory:** Can be either `A` (occasional user) or `B` (frequent user). Data type: `object`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "1_min"
    ]
   },
   "source": [
    "## Format\n",
    "\n",
    "![Format icon](data/images/format.jpg)\n",
    "\n",
    "As mentioned during lecture, we will be handing our dataset as a `.csv` file encoded using `UTF-8`. We will make sure that these two requirements are met by exporting our file with the `df.to_csv(\"clean.csv\", encoding=\"utf-8\")` command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "1_min"
    ]
   },
   "source": [
    "## Relevance\n",
    "\n",
    "![Relevance icon](data/images/relevance.jpg)\n",
    "\n",
    "We said that we needed to:\n",
    "\n",
    "* Replace each missing `Bike Id` with the \"Not available\" string\n",
    "* Interpolate the missing values in the `userCategory` column\n",
    "* Replace each missing `EndStation Id` with the \"Not available\" string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "### Example 1\n",
    "\n",
    "Replace the missing values in `bike_id` and `end_station_id` with the \"Not Available\" string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** There are a number of ways to do this, but we will do so with the [**`.fillna()`**](https://pandas.pydata.org/docs/reference/api/pandas.Series.fillna.html) Series function. This function takes a single argument and replaces all `NaN` values in the Series with the value of that argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Bike Id\"] = df[\"Bike Id\"].fillna('Not available')\n",
    "df[\"EndStation Id\"] = df[\"EndStation Id\"].fillna('Not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "12_min"
    ]
   },
   "source": [
    "### Interpolating missing values\n",
    "\n",
    "To do the interpolation for `userCategory`, we can use the [**`.interpolate()`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.interpolate.html) method in `pandas`. The `interpolate()` method uses linear interpolation, which is a mathematical method for filling in unknown points based on building a linear regression model on the non-missing points (you will learn more about linear regression in future cases). We can then use this model to estimate the values of the missing points. This is *very* different from substituting null values with random or meaningless values, as it *preserves aspects of the distribution of the data, which can be very important for certain analyses*.\n",
    "\n",
    "But `userCategory` is a string - how can we apply a mathematical model to a string? Luckily, `userCategory` can only take on two values, so we can convert it to a `category` type with `.astype()` and then run the interpolation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a category type\n",
    "df['userCategory'] = df['userCategory'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After converting `userCategory` to be a category column, let's see what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['['A']', '['B']'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The categories\n",
    "df['userCategory'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1, -1], dtype=int8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the codes assigned to the categories\n",
    "df['userCategory'].cat.codes.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see there are 2 codes here: 0 and 1, which correspond to the two values `['A']` and `['B']`. (The number -1 represents the NaN values.) In order to interpolate the values, we need to call the `.interpolate()` method after having replaced the -1s with actual null values (`np.nan`s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1       1.0\n",
       "2       0.0\n",
       "3       0.0\n",
       "4       0.0\n",
       "       ... \n",
       "9995    0.0\n",
       "9996    0.0\n",
       "9997    0.0\n",
       "9998    0.0\n",
       "9999    1.0\n",
       "Length: 10000, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The below code replaces the value -1 with NaN\n",
    "user_cat_codes = df['userCategory'].cat.codes.replace(-1, np.nan)\n",
    "\n",
    "# We now call the interpolate function that actually fills the NaN values with either a 0 or 1\n",
    "user_cat_codes = user_cat_codes.interpolate()\n",
    "user_cat_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert the codes to the `category` data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_cat_codes = user_cat_codes.astype(int).astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we replace back the 0s and 1s with the actual category names. For this, we can use the **`.cat.rename_categories()`** method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ['A']\n",
       "1       ['B']\n",
       "2       ['A']\n",
       "3       ['A']\n",
       "4       ['A']\n",
       "        ...  \n",
       "9995    ['A']\n",
       "9996    ['A']\n",
       "9997    ['A']\n",
       "9998    ['A']\n",
       "9999    ['B']\n",
       "Name: userCategory, Length: 10000, dtype: category\n",
       "Categories (2, object): ['['A']', '['B']']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_cat_codes = user_cat_codes.cat.rename_categories(df['userCategory'].cat.categories)\n",
    "df['userCategory'] = user_cat_codes\n",
    "df['userCategory']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "1_min"
    ]
   },
   "source": [
    "## Consistency\n",
    "\n",
    "![Consistency icon](data/images/consistency.jpg)\n",
    "\n",
    "### Data type consistency\n",
    "\n",
    "From our previous examination of the dataset, we decided that these changes had to be made:\n",
    "\n",
    "| Column | Current data type | Convert to |\n",
    "| --- | --- | --- |\n",
    "| `Rental Id` | `int64` | `category` |\n",
    "| `Bike Id` | `int64` | `category` |\n",
    "| `End Date` | `object` | `datetime` |\n",
    "| `EndStation Id` | `int64` | `category` |\n",
    "| `Start Date` | `object` | `datetime` |\n",
    "| `StartStation Id` | `int64` | `category` |\n",
    "| `tag` | `object` | `category` |\n",
    "| `userCategory` | `object` | `category` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "### Exercise 1\n",
    "\n",
    "To change the data type of a Series in `pandas`, we use the `.astype()` method that you learned in previous cases. Make the changes for all the columns except for `Start Date` and `End Date` (we will explain how to do those shortly). You also do not need to convert `userCategory` since we already did that when we interpolated its missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rental Id'] = df['Rental Id'].astype('category')\n",
    "df['Bike Id'] = df['Bike Id'].astype('category')\n",
    "df['EndStation Id'] = df['EndStation Id'].astype('category')\n",
    "df['tag'] = df['tag'].astype('category')\n",
    "df['userCategory'] = df['userCategory'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "3_min"
    ]
   },
   "source": [
    "### Converting dates\n",
    "\n",
    "This is a typical date in the dataset: `12/08/2020 16:28`. It follows the `DD/MM/YYYY` date format, and the 24 hour time format. The date and the time are separated by a space. To convert this kind of data into a `datetime` column, we use the **`pd.to_datetime()`** function like this (this function automatically detects the format, so we don't have to worry about that):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Start Date\"] = pd.to_datetime(df[\"Start Date\"])\n",
    "df[\"End Date\"] = pd.to_datetime(df[\"End Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "### Exercise 2\n",
    "\n",
    "In terms of unit consistency, we need to create a new column, `duration_min`, that is the duration of the journeys in minutes instead of seconds. Create the column in `df`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration_min'] = df['Duration']/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now remove the `Duration` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Duration\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "3_min"
    ]
   },
   "source": [
    "### Categorical consistency\n",
    "\n",
    "We noticed that in `tag` we are supposed to have only three categories, `low`, `medium`, and `high`, but according to our report, we have five. A closer look at our DataFrame reveals that we have these labels: \"priority low\", \"Priority low\", \"priority_high\", \"priority_medium\", and \"priority Medium\". We need to standardize these. We can make a replacement dictionary and rename our categories with this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       medium\n",
       "1       medium\n",
       "2       medium\n",
       "3       medium\n",
       "4       medium\n",
       "         ...  \n",
       "9995       low\n",
       "9996      high\n",
       "9997       low\n",
       "9998       low\n",
       "9999    medium\n",
       "Name: tag, Length: 10000, dtype: category\n",
       "Categories (3, object): ['high', 'low', 'medium']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rename_dict = {\"Priority low\":\"low\",\n",
    "               \"priority_high\":\"high\",\n",
    "               \"priority Medium\":\"medium\",\n",
    "               \"priority_medium\":\"medium\",\n",
    "               \"priority low\":\"low\"\n",
    "              }\n",
    "df[\"tag\"] = df[\"tag\"].replace(rename_dict).astype(\"category\")\n",
    "df[\"tag\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "### Exercise 3\n",
    "\n",
    "Do the appropriate replacements for the `userCategory` column (it has some weird formatting - `['A']` and `['B']` instead of `A` and `B`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalDtype(categories=['A', 'B'], ordered=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userCategory_dict = {\"['A']\":\"A\",\n",
    "                     \"['B']\":\"B\"}\n",
    "\n",
    "df['userCategory']= df['userCategory'].replace(userCategory_dict).astype(\"category\")\n",
    "\n",
    "df['userCategory'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "### Referential integrity\n",
    "\n",
    "We now need to remove the duplicates in the dataset. The method of choice is [**`.drop_duplicates()`**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html). When you use this method on a Series or DataFrame, it removes all the duplicate rows (keeping only the first occurrence) and then outputs the Series or DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default in `.drop_duplicates()` when used on a DataFrame is to treat as duplicates only the rows that are equal in all of their fields, but you can also ask `pandas` to check for duplicity only on a subset of the fields, using the `subset` argument.\n",
    "\n",
    "We also need to create trip IDs. When generating unique identifiers for datasets like this, we should make sure the generation process is **idempotent** (i.e. the same ID should be generated for each trip no matter how many times you run the script). This is required because there may be chances that the same trip is inputted into this tool multiple times. For example, suppose the customer first uploads the dataset for the first week of the month (for testing purposes, or based on data availability, etc.), and later uploads the dataset for the entire month. Now, if the same trip is assigned different IDs for each upload, then it might result in the analytics platform interpreting this as two different trips and this will skew the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "15_min"
    ]
   },
   "source": [
    "### Exercise 4\n",
    "\n",
    "Describe how you would generate a unique ID per trip while guaranteeing idempotence, then write code to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjMyOjAwOjEyODI5LjA=',\n",
       "       'MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU2OjAwOjEwODYzLjA=',\n",
       "       'MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU2OjAwOjM5OTcuMA==',\n",
       "       ...,\n",
       "       'MjAyMC0wMy0wOSAxMTo0MTowMDoyMDIwLTAzLTA5IDExOjUxOjAwOjg1NjAuMA==',\n",
       "       'MjAyMC0wNS0wOSAyMDoyMTowMDoyMDIwLTA1LTA5IDIwOjQ3OjAwOjE2NjI2LjA=',\n",
       "       'MjAyMC0wNi0wOSAxNzoxMjowMDoyMDIwLTA2LTA5IDE3OjI1OjAwOjE2OTYxLjA='],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's generate an id for each trip, in order to uniquely identify each trip. \n",
    "# The trip id can be a combination of start date, end date, and bike id\n",
    "df['trip_id'] = df.apply(lambda x: ':'.join([str(x['Start Date']), str(x['End Date']), str(x['Bike Id'])]), axis=1)\n",
    "\n",
    "# In order for the id to look actually like a unique identifier, let's use base64 encode to convert the id to a base64 string\n",
    "# The command converts the newly created id column into bytes, and then gets the base64 encoded value for the same. \n",
    "# Then the base64 value is converted to string again and then stored in the trip_id column.\n",
    "df['trip_id'] = df['trip_id'].apply(lambda x: base64.b64encode(x.encode()).decode())\n",
    "\n",
    "#checking to see if what you wanted to happen happened\n",
    "df['trip_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "3_min"
    ]
   },
   "source": [
    "### Column name consistency\n",
    "\n",
    "### Example 2\n",
    "\n",
    "Rename the columns so that they are in all-lowercase and separate words with underscores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer.** We can use the **`.rename()`** method to do this efficiently. Similar to `replace()`, this method can also take a dictionary as its argument to compress the amount of necessary code-writing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rental_id', 'bike_id', 'end_date', 'end_station_id', 'start_date',\n",
       "       'start_station_id', 'tag', 'user_category', 'duration_min', 'trip_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_dict = {\"Rental Id\":\"rental_id\",\n",
    "                \"Duration\":\"duration\",\n",
    "                \"Bike Id\":\"bike_id\",\n",
    "                \"End Date\":\"end_date\",\n",
    "                \"EndStation Id\":\"end_station_id\",\n",
    "                \"Start Date\":\"start_date\",\n",
    "                \"StartStation Id\":\"start_station_id\",\n",
    "                \"userCategory\":\"user_category\"\n",
    "               }\n",
    "df = df.rename(columns=columns_dict)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "2_min"
    ]
   },
   "source": [
    "## Data augmentation\n",
    "\n",
    "![Data augmentation](data/images/data_augmentation.jpg)\n",
    "\n",
    "Our priorities are:\n",
    "\n",
    "1. Merging `trips.csv` with `stations.json`\n",
    "2. Creating the following features:\n",
    "    1. Day of the week for both `start_date` and `end_date`\n",
    "    2. Hour for both `start_date` and `end_date`\n",
    "    3. Total cost of the rental\n",
    "    4. Location (the general area where the station is located). In the `stations.json` file, these are the strings after the comma in `Station name`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "25_min"
    ]
   },
   "source": [
    "### Merging the datasets\n",
    "\n",
    "To merge the two datasets, we first need to load `stations.json` into `pandas`. For this, we will use the [**`pd.read_json()`**](https://pandas.pydata.org/docs/reference/api/pandas.read_json.html) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station ID</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Station Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>51.529163</td>\n",
       "      <td>-0.109970</td>\n",
       "      <td>River Street , Clerkenwell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>51.499606</td>\n",
       "      <td>-0.197574</td>\n",
       "      <td>Phillimore Gardens, Kensington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>51.521283</td>\n",
       "      <td>-0.084605</td>\n",
       "      <td>Christopher Street, Liverpool Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>51.530059</td>\n",
       "      <td>-0.120973</td>\n",
       "      <td>St. Chad's Street, King's Cross</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>51.493130</td>\n",
       "      <td>-0.156876</td>\n",
       "      <td>Sedding Street, Sloane Square</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Station ID   Latitude  Longitude                          Station Name\n",
       "0           1  51.529163  -0.109970            River Street , Clerkenwell\n",
       "1           2  51.499606  -0.197574        Phillimore Gardens, Kensington\n",
       "2           3  51.521283  -0.084605  Christopher Street, Liverpool Street\n",
       "3           4  51.530059  -0.120973       St. Chad's Street, King's Cross\n",
       "4           5  51.493130  -0.156876         Sedding Street, Sloane Square"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations = pd.read_json(\"data/stations.json\", orient=\"columns\")\n",
    "stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JSON files** are very similar to Python dictionaries. They are basically text files whose content is a dictionary that can be read by any major programming language.\n",
    "\n",
    "JSON files are sometimes used instead of CSV files to share data because in some cases they take up less memory. With `pd.read_json()`, you can read files like this and turn them into DataFrames with a single line of code. Depending on how the JSON file is built, you can specify the orientation with the `orient` argument. Above, we used `orient=\"columns\"` because the `stations.json` file's structure follows this pattern:\n",
    "\n",
    "~~~json\n",
    "{\n",
    "   \"col 1\":{\n",
    "      \"row 1\":\"This is column 1, row 1\",\n",
    "      \"row 2\":\"This is column 1, row 2\"\n",
    "   },\n",
    "   \"col 2\":{\n",
    "      \"row 1\":\"This is column 2, row 1\",\n",
    "      \"row 2\":\"This is column 2, row 2\"\n",
    "   }\n",
    "}\n",
    "~~~\n",
    "\n",
    "But let's say you have a file like this:\n",
    "\n",
    "~~~json\n",
    "{\n",
    "   \"row 1\":{\n",
    "      \"col 1\":\"This is row 1, column 1\",\n",
    "      \"col 2\":\"This is row 1, column 2\"\n",
    "   },\n",
    "   \"row 2\":{\n",
    "      \"col 1\":\"This is row 2, column 1\",\n",
    "      \"col 2\":\"This is row 2, column 2\"\n",
    "   }\n",
    "}\n",
    "~~~\n",
    "\n",
    "The correct way to read it would be using `orient=\"index\"` (since the default integer indexes in a DataFrame refer to rows, this makes logical sense)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col 1</th>\n",
       "      <th>col 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>row 1</th>\n",
       "      <td>This is row 1, column 1</td>\n",
       "      <td>This is row 1, column 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row 2</th>\n",
       "      <td>This is row 2, column 1</td>\n",
       "      <td>This is row 2, column 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         col 1                    col 2\n",
       "row 1  This is row 1, column 1  This is row 1, column 2\n",
       "row 2  This is row 2, column 1  This is row 2, column 2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = \"\"\"{\n",
    "   \"row 1\":{\n",
    "      \"col 1\":\"This is row 1, column 1\",\n",
    "      \"col 2\":\"This is row 1, column 2\"\n",
    "   },\n",
    "   \"row 2\":{\n",
    "      \"col 1\":\"This is row 2, column 1\",\n",
    "      \"col 2\":\"This is row 2, column 2\"\n",
    "   }\n",
    "}\"\"\"\n",
    "\n",
    "pd.read_json(j, orient=\"index\") # Try changing \"index\" for \"columns\" to see what happens!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create the `location` column here before doing the merge. For that, we use the [**`.str.split()`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.split.html) method. This method takes all the strings of a string Series and splits them using instances of a particular character within those strings. One common use case is when you have a column with strings that look like this:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">  <thead>    <tr style=\"text-align: right;\">      <th></th>      <th>my_series</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>Houston,Texas,United States</td>    </tr>    <tr>      <th>1</th>      <td>Toronto,Ontario,Canada</td>    </tr>    <tr>      <th>2</th>      <td>Tucson,Arizona,United States</td>    </tr>  </tbody></table>\n",
    "\n",
    "\n",
    "You can split these values using the comma as a separator with the code `my_series.str.split(pat=\",\")` to get this result:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">  <thead>    <tr style=\"text-align: right;\">      <th></th>      <th>my_series_split</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>[Houston, Texas, United States]</td>    </tr>    <tr>      <th>1</th>      <td>[Toronto, Ontario, Canada]</td>    </tr>    <tr>      <th>2</th>      <td>[Tucson, Arizona, United States]</td>    </tr>  </tbody></table>\n",
    "\n",
    "Notice how each string in this Series was turned into a list, where each element of this list was derived from the characters between consecutive instances of the \",\" character (or between the start of the string and the first \",\" for the first element, and the last \",\" and the end of the string for the last element).\n",
    "\n",
    "If you want the split values to be represented as columns of a DataFrame instead of lists inside a column, we can add the `expand=True` argument like this: `my_series.str.split(pat=\",\", expand=True)`. This is the result:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">  <thead>    <tr style=\"text-align: right;\">      <th></th>      <th>0</th>      <th>1</th>      <th>2</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>Houston</td>      <td>Texas</td>      <td>United States</td>    </tr>    <tr>      <th>1</th>      <td>Toronto</td>      <td>Ontario</td>      <td>Canada</td>    </tr>    <tr>      <th>2</th>      <td>Tucson</td>      <td>Arizona</td>      <td>United States</td>    </tr>  </tbody></table>\n",
    "\n",
    "Let's now apply this to our read-in JSON file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>River Street</td>\n",
       "      <td>Clerkenwell</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phillimore Gardens</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christopher Street</td>\n",
       "      <td>Liverpool Street</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>St. Chad's Street</td>\n",
       "      <td>King's Cross</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sedding Street</td>\n",
       "      <td>Sloane Square</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                  1     2\n",
       "0       River Street         Clerkenwell  None\n",
       "1  Phillimore Gardens         Kensington  None\n",
       "2  Christopher Street   Liverpool Street  None\n",
       "3   St. Chad's Street       King's Cross  None\n",
       "4      Sedding Street      Sloane Square  None"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_columns = stations[\"Station Name\"].str.split(pat=\",\", expand=True)\n",
    "split_columns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoops! Somehow a third column got appended and it seems to be `None` for all of the rows. How can this be? Well, if this is happening, it's likely that there is *some* station name which has TWO commas in it, and so it is getting split properly into three columns. But most other station names only have ONE comma in them, so splitting those into three columns would necessarily mean the last column would be empty. Let's see if we're right by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Stockwell          1\n",
       " Wandsworth Road    1\n",
       "Name: 2, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_columns[2].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems there are two stations with two commas in them. In order to deal with this, we use the `n` argument, which tells `pandas` the maximum number of splits `str.split()` should perform. For instance, you could use `my_string.str.split(pat=\",\", n=1, expand=True)` to split only at the first comma and get this result. Let's apply this to our read-in JSON file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>River Street</td>\n",
       "      <td>Clerkenwell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phillimore Gardens</td>\n",
       "      <td>Kensington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christopher Street</td>\n",
       "      <td>Liverpool Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>St. Chad's Street</td>\n",
       "      <td>King's Cross</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sedding Street</td>\n",
       "      <td>Sloane Square</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                  1\n",
       "0       River Street         Clerkenwell\n",
       "1  Phillimore Gardens         Kensington\n",
       "2  Christopher Street   Liverpool Street\n",
       "3   St. Chad's Street       King's Cross\n",
       "4      Sedding Street      Sloane Square"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_columns = stations[\"Station Name\"].str.split(pat=\",\", n=1, expand=True)\n",
    "split_columns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go! Now we simply add these columns to `stations` and do the corresponding adjustments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>station_name</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>51.529163</td>\n",
       "      <td>-0.109970</td>\n",
       "      <td>River Street</td>\n",
       "      <td>Clerkenwell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>51.499606</td>\n",
       "      <td>-0.197574</td>\n",
       "      <td>Phillimore Gardens</td>\n",
       "      <td>Kensington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>51.521283</td>\n",
       "      <td>-0.084605</td>\n",
       "      <td>Christopher Street</td>\n",
       "      <td>Liverpool Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>51.530059</td>\n",
       "      <td>-0.120973</td>\n",
       "      <td>St. Chad's Street</td>\n",
       "      <td>King's Cross</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>51.493130</td>\n",
       "      <td>-0.156876</td>\n",
       "      <td>Sedding Street</td>\n",
       "      <td>Sloane Square</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station_id   latitude  longitude        station_name           location\n",
       "0          1  51.529163  -0.109970       River Street         Clerkenwell\n",
       "1          2  51.499606  -0.197574  Phillimore Gardens         Kensington\n",
       "2          3  51.521283  -0.084605  Christopher Street   Liverpool Street\n",
       "3          4  51.530059  -0.120973   St. Chad's Street       King's Cross\n",
       "4          5  51.493130  -0.156876      Sedding Street      Sloane Square"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations = pd.concat([stations, split_columns], axis=1)\n",
    "rename_dict = {\n",
    "    0:\"station_name\",\n",
    "    1:\"location\",\n",
    "    \"Latitude\":\"latitude\",\n",
    "    \"Longitude\":\"longitude\",\n",
    "    \"Station ID\":\"station_id\"\n",
    "}\n",
    "stations = stations.rename(columns=rename_dict)\n",
    "stations = stations.drop(columns=[\"Station Name\"])\n",
    "stations[\"station_id\"] = stations[\"station_id\"].astype(\"category\") # We need this to be a category feature\n",
    "stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also use **`str.strip()`** to get rid of leading and trailing spaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations[\"station_name\"] = stations[\"station_name\"].str.strip()\n",
    "stations[\"location\"] = stations[\"location\"].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [`str.strip()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.strip.html) method takes all the strings in a Series and removes any leading or trailing whitespaces in them. After being processed with this method, a string like \"   hello world! \" will, for instance, be stripped to become \"hello world!\".\n",
    "\n",
    "You can also specify a custom character to remove with the `to_strip` argument (e.g. to remove `_`s you would use `my_series.str.strip(to_strip=\"_\")`, and \"\\_hello world!\\_\" would become \"hello world!\"), rather than removing whitespaces.\n",
    "\n",
    "To merge the datasets, we use `pd.merge()`. For `start_station_id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rental_id</th>\n",
       "      <th>bike_id</th>\n",
       "      <th>end_date</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>tag</th>\n",
       "      <th>user_category</th>\n",
       "      <th>duration_min</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>start_latitude</th>\n",
       "      <th>start_longitude</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101428476</td>\n",
       "      <td>12829.0</td>\n",
       "      <td>2020-03-09 20:32:00</td>\n",
       "      <td>132.0</td>\n",
       "      <td>2020-03-09 20:04:00</td>\n",
       "      <td>574</td>\n",
       "      <td>medium</td>\n",
       "      <td>A</td>\n",
       "      <td>28.0</td>\n",
       "      <td>MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOj...</td>\n",
       "      <td>51.533560</td>\n",
       "      <td>-0.093150</td>\n",
       "      <td>Eagle Wharf Road</td>\n",
       "      <td>Hoxton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101522714</td>\n",
       "      <td>10863.0</td>\n",
       "      <td>2020-06-09 12:56:00</td>\n",
       "      <td>702.0</td>\n",
       "      <td>2020-06-09 12:11:00</td>\n",
       "      <td>82</td>\n",
       "      <td>medium</td>\n",
       "      <td>B</td>\n",
       "      <td>45.0</td>\n",
       "      <td>MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOj...</td>\n",
       "      <td>51.514274</td>\n",
       "      <td>-0.111257</td>\n",
       "      <td>Chancery Lane</td>\n",
       "      <td>Holborn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101377356</td>\n",
       "      <td>3997.0</td>\n",
       "      <td>2020-02-09 10:56:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2020-02-09 10:49:00</td>\n",
       "      <td>225</td>\n",
       "      <td>medium</td>\n",
       "      <td>A</td>\n",
       "      <td>7.0</td>\n",
       "      <td>MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOj...</td>\n",
       "      <td>51.509353</td>\n",
       "      <td>-0.196422</td>\n",
       "      <td>Notting Hill Gate Station</td>\n",
       "      <td>Notting Hill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101393663</td>\n",
       "      <td>16542.0</td>\n",
       "      <td>2020-02-09 18:40:00</td>\n",
       "      <td>622.0</td>\n",
       "      <td>2020-02-09 18:29:00</td>\n",
       "      <td>97</td>\n",
       "      <td>medium</td>\n",
       "      <td>A</td>\n",
       "      <td>11.0</td>\n",
       "      <td>MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4Oj...</td>\n",
       "      <td>51.497924</td>\n",
       "      <td>-0.183834</td>\n",
       "      <td>Gloucester Road (North)</td>\n",
       "      <td>Kensington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101622659</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>2020-08-09 19:57:00</td>\n",
       "      <td>219.0</td>\n",
       "      <td>2020-08-09 19:46:00</td>\n",
       "      <td>36</td>\n",
       "      <td>medium</td>\n",
       "      <td>A</td>\n",
       "      <td>11.0</td>\n",
       "      <td>MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5Oj...</td>\n",
       "      <td>51.501737</td>\n",
       "      <td>-0.184980</td>\n",
       "      <td>De Vere Gardens</td>\n",
       "      <td>Kensington</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rental_id  bike_id            end_date end_station_id          start_date  \\\n",
       "0  101428476  12829.0 2020-03-09 20:32:00          132.0 2020-03-09 20:04:00   \n",
       "1  101522714  10863.0 2020-06-09 12:56:00          702.0 2020-06-09 12:11:00   \n",
       "2  101377356   3997.0 2020-02-09 10:56:00           97.0 2020-02-09 10:49:00   \n",
       "3  101393663  16542.0 2020-02-09 18:40:00          622.0 2020-02-09 18:29:00   \n",
       "4  101622659   1605.0 2020-08-09 19:57:00          219.0 2020-08-09 19:46:00   \n",
       "\n",
       "   start_station_id     tag user_category  duration_min  \\\n",
       "0               574  medium             A          28.0   \n",
       "1                82  medium             B          45.0   \n",
       "2               225  medium             A           7.0   \n",
       "3                97  medium             A          11.0   \n",
       "4                36  medium             A          11.0   \n",
       "\n",
       "                                             trip_id  start_latitude  \\\n",
       "0  MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOj...       51.533560   \n",
       "1  MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOj...       51.514274   \n",
       "2  MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOj...       51.509353   \n",
       "3  MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4Oj...       51.497924   \n",
       "4  MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5Oj...       51.501737   \n",
       "\n",
       "   start_longitude         start_station_name start_location  \n",
       "0        -0.093150           Eagle Wharf Road         Hoxton  \n",
       "1        -0.111257              Chancery Lane        Holborn  \n",
       "2        -0.196422  Notting Hill Gate Station   Notting Hill  \n",
       "3        -0.183834    Gloucester Road (North)     Kensington  \n",
       "4        -0.184980            De Vere Gardens     Kensington  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df, stations, left_on=\"start_station_id\", right_on=\"station_id\", how=\"left\")\n",
    "\n",
    "rename_dict = {\n",
    "    \"latitude\":\"start_latitude\",\n",
    "    \"longitude\":\"start_longitude\",\n",
    "    \"station_name\":\"start_station_name\",\n",
    "    \"location\":\"start_location\"\n",
    "}\n",
    "df = df.rename(columns=rename_dict)\n",
    "# Remove the extra column that was added\n",
    "df = df.drop(columns=[\"station_id\"])\n",
    "# Fill any remaining nulls with \"Not Available\" - only for string columns\n",
    "obj_cols = df.columns[df.dtypes==\"object\"]\n",
    "df[obj_cols] = df[obj_cols].fillna('Not Available')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "### Exercise 5\n",
    "\n",
    "Copy the code above and paste it in a new cell. Modify it to do the merge for the end stations this time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-0d2034920ab3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Fill any remaining nulls with \"Not Available\" - only for string columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mobj_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"object\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj_cols\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not Available'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m#peek-a-boo! let's see what happened\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3158\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3159\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3160\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3161\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3162\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3188\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3189\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Columns must be same length as key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3190\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3191\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "df = pd.merge(df, stations, left_on=\"end_station_id\", right_on=\"station_id\", how=\"left\")\n",
    "# create a replacement dictionary\n",
    "rename_dict = {\n",
    "    \"latitude\":\"end_latitude\",\n",
    "    \"longitude\":\"end_longitude\",\n",
    "    \"station_name\":\"end_station_name\",\n",
    "    \"location\":\"end_location\"\n",
    "}\n",
    "#apply the replacement dictionary to the df \n",
    "df = df.rename(columns=rename_dict)\n",
    "# Remove the extra column that was added\n",
    "df = df.drop(columns=[\"station_id\"])\n",
    "# Fill any remaining nulls with \"Not Available\" - only for string columns\n",
    "obj_cols = df.columns[df.dtypes==\"object\"]\n",
    "df[obj_cols] = df[obj_cols].fillna('Not Available')\n",
    "#peek-a-boo! let's see what happened\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "2_min"
    ]
   },
   "source": [
    "### Feature engineering\n",
    "\n",
    "Finally, let's create the `start_weekday`, `start_hour`, and `rental_cost` features. We start with the first two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've generated the merged df DataFrame for you, but you will have to figure out the code we used (in Exercise 5)!\n",
    "df = pd.read_csv(\"data/df_exercise.csv\", parse_dates=[\"start_date\"])\n",
    "\n",
    "df['start_hour'] = df['start_date'].dt.hour # dt.hour gets you the hour\n",
    "df['start_weekday'] = df['start_date'].dt.weekday # dt.weekday gets you the weekday (as an integer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we used the [**`dt.hour`**](https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.hour.html) and [**`dt.weekday`**](https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.weekday.html) attributes. These only work with columns that are of type `datetime`. These basically acess the hour and the weekday of the `datetime`. (Observe that you have to add `dt` before you call these attributes.) Other attributes include `dt.tz` (timezone), `dt.year`, `dt.month`, `dt.day`, `dt.minute`, and `dt.second`, [amongst others](https://pandas.pydata.org/docs/reference/series.html#datetimelike-properties)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "15_min"
    ]
   },
   "source": [
    "### Exercise 6 (optional)\n",
    "\n",
    "Create the `rental_cost` DataFrame. Remember that you have to pay Â£2 upfront for your rental, and then you can have as many rides as you want without paying more, so long as you don't exceed 30 minutes in each ride. If you exceed this threshold, you have to pay Â£2 for each 30-minute block (a fraction of a block counts as a full block).\n",
    "\n",
    "The DataFrame should look like this:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">  <thead>    <tr style=\"text-align: right;\">      <th></th>      <th>rental_id</th>      <th>rental_cost</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>101368080</td>      <td>2</td>    </tr>    <tr>      <th>1</th>      <td>101368081</td>      <td>2</td>    </tr>    <tr>      <th>2</th>      <td>101368082</td>      <td>2</td>    </tr>    <tr>      <th>3</th>      <td>101368083</td>      <td>2</td>    </tr>    <tr>      <th>4</th>      <td>101368084</td>      <td>2</td>    </tr>    <tr>      <th>5</th>      <td>101368086</td>      <td>2</td>    </tr>    <tr>      <th>6</th>      <td>101368172</td>      <td>2</td>    </tr>    <tr>      <th>7</th>      <td>101368173</td>      <td>2</td>    </tr>    <tr>      <th>8</th>      <td>101368174</td>      <td>2</td>    </tr>    <tr>      <th>9</th>      <td>101368176</td>      <td>2</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>    </tr>  </tbody></table>\n",
    "\n",
    "**Hint:** To round a float number up, you can use the [`.ceil()`](https://www.w3schools.com/python/ref_math_ceil.asp) function from the `math` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ans_st"
    ]
   },
   "source": [
    "**Answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rental_id</th>\n",
       "      <th>bike_id</th>\n",
       "      <th>end_date</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>tag</th>\n",
       "      <th>user_category</th>\n",
       "      <th>duration_min</th>\n",
       "      <th>start_latitude</th>\n",
       "      <th>...</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_location</th>\n",
       "      <th>end_latitude</th>\n",
       "      <th>end_longitude</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_location</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>start_weekday</th>\n",
       "      <th>rental_cost</th>\n",
       "      <th>time_blocks</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjMyOjAwOjEyODI5LjA=</th>\n",
       "      <td>101428476</td>\n",
       "      <td>12829.0</td>\n",
       "      <td>2020-03-09 20:32:00</td>\n",
       "      <td>132.0</td>\n",
       "      <td>2020-03-09 20:04:00</td>\n",
       "      <td>574</td>\n",
       "      <td>medium</td>\n",
       "      <td>A</td>\n",
       "      <td>28.0</td>\n",
       "      <td>51.533560</td>\n",
       "      <td>...</td>\n",
       "      <td>Eagle Wharf Road</td>\n",
       "      <td>Hoxton</td>\n",
       "      <td>51.523648</td>\n",
       "      <td>-0.074754</td>\n",
       "      <td>Bethnal Green Road</td>\n",
       "      <td>Shoreditch</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU2OjAwOjEwODYzLjA=</th>\n",
       "      <td>101522714</td>\n",
       "      <td>10863.0</td>\n",
       "      <td>2020-06-09 12:56:00</td>\n",
       "      <td>702.0</td>\n",
       "      <td>2020-06-09 12:11:00</td>\n",
       "      <td>82</td>\n",
       "      <td>medium</td>\n",
       "      <td>B</td>\n",
       "      <td>45.0</td>\n",
       "      <td>51.514274</td>\n",
       "      <td>...</td>\n",
       "      <td>Chancery Lane</td>\n",
       "      <td>Holborn</td>\n",
       "      <td>51.528681</td>\n",
       "      <td>-0.065550</td>\n",
       "      <td>Durant Street</td>\n",
       "      <td>Bethnal Green</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU2OjAwOjM5OTcuMA==</th>\n",
       "      <td>101377356</td>\n",
       "      <td>3997.0</td>\n",
       "      <td>2020-02-09 10:56:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2020-02-09 10:49:00</td>\n",
       "      <td>225</td>\n",
       "      <td>medium</td>\n",
       "      <td>A</td>\n",
       "      <td>7.0</td>\n",
       "      <td>51.509353</td>\n",
       "      <td>...</td>\n",
       "      <td>Notting Hill Gate Station</td>\n",
       "      <td>Notting Hill</td>\n",
       "      <td>51.497924</td>\n",
       "      <td>-0.183834</td>\n",
       "      <td>Gloucester Road (North)</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQwOjAwOjE2NTQyLjA=</th>\n",
       "      <td>101393663</td>\n",
       "      <td>16542.0</td>\n",
       "      <td>2020-02-09 18:40:00</td>\n",
       "      <td>622.0</td>\n",
       "      <td>2020-02-09 18:29:00</td>\n",
       "      <td>97</td>\n",
       "      <td>medium</td>\n",
       "      <td>A</td>\n",
       "      <td>11.0</td>\n",
       "      <td>51.497924</td>\n",
       "      <td>...</td>\n",
       "      <td>Gloucester Road (North)</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>51.507481</td>\n",
       "      <td>-0.205535</td>\n",
       "      <td>Lansdowne Road</td>\n",
       "      <td>Ladbroke Grove</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU3OjAwOjE2MDUuMA==</th>\n",
       "      <td>101622659</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>2020-08-09 19:57:00</td>\n",
       "      <td>219.0</td>\n",
       "      <td>2020-08-09 19:46:00</td>\n",
       "      <td>36</td>\n",
       "      <td>medium</td>\n",
       "      <td>A</td>\n",
       "      <td>11.0</td>\n",
       "      <td>51.501737</td>\n",
       "      <td>...</td>\n",
       "      <td>De Vere Gardens</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>51.490163</td>\n",
       "      <td>-0.190393</td>\n",
       "      <td>Bramham Gardens</td>\n",
       "      <td>Earl's Court</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    rental_id  bike_id  \\\n",
       "trip_id                                                                  \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...  101428476  12829.0   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...  101522714  10863.0   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...  101377356   3997.0   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...  101393663  16542.0   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...  101622659   1605.0   \n",
       "\n",
       "                                                               end_date  \\\n",
       "trip_id                                                                   \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...  2020-03-09 20:32:00   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...  2020-06-09 12:56:00   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...  2020-02-09 10:56:00   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...  2020-02-09 18:40:00   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...  2020-08-09 19:57:00   \n",
       "\n",
       "                                                   end_station_id  \\\n",
       "trip_id                                                             \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...          132.0   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...          702.0   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...           97.0   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...          622.0   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...          219.0   \n",
       "\n",
       "                                                            start_date  \\\n",
       "trip_id                                                                  \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM... 2020-03-09 20:04:00   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU... 2020-06-09 12:11:00   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU... 2020-02-09 10:49:00   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ... 2020-02-09 18:29:00   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU... 2020-08-09 19:46:00   \n",
       "\n",
       "                                                    start_station_id     tag  \\\n",
       "trip_id                                                                        \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...               574  medium   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...                82  medium   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...               225  medium   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...                97  medium   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...                36  medium   \n",
       "\n",
       "                                                   user_category  \\\n",
       "trip_id                                                            \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...             A   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...             B   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...             A   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...             A   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...             A   \n",
       "\n",
       "                                                    duration_min  \\\n",
       "trip_id                                                            \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...          28.0   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...          45.0   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...           7.0   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...          11.0   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...          11.0   \n",
       "\n",
       "                                                    start_latitude  ...  \\\n",
       "trip_id                                                             ...   \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...       51.533560  ...   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...       51.514274  ...   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...       51.509353  ...   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...       51.497924  ...   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...       51.501737  ...   \n",
       "\n",
       "                                                           start_station_name  \\\n",
       "trip_id                                                                         \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...           Eagle Wharf Road   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...              Chancery Lane   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...  Notting Hill Gate Station   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...    Gloucester Road (North)   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...            De Vere Gardens   \n",
       "\n",
       "                                                   start_location  \\\n",
       "trip_id                                                             \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...         Hoxton   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...        Holborn   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...   Notting Hill   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...     Kensington   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...     Kensington   \n",
       "\n",
       "                                                   end_latitude  \\\n",
       "trip_id                                                           \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...    51.523648   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...    51.528681   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...    51.497924   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...    51.507481   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...    51.490163   \n",
       "\n",
       "                                                    end_longitude  \\\n",
       "trip_id                                                             \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...      -0.074754   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...      -0.065550   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...      -0.183834   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...      -0.205535   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...      -0.190393   \n",
       "\n",
       "                                                           end_station_name  \\\n",
       "trip_id                                                                       \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...       Bethnal Green Road   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...            Durant Street   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...  Gloucester Road (North)   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...           Lansdowne Road   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...          Bramham Gardens   \n",
       "\n",
       "                                                      end_location start_hour  \\\n",
       "trip_id                                                                         \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...      Shoreditch         20   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...   Bethnal Green         12   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...      Kensington         10   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...  Ladbroke Grove         18   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...    Earl's Court         19   \n",
       "\n",
       "                                                    start_weekday  \\\n",
       "trip_id                                                             \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...              0   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...              1   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...              6   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...              6   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...              6   \n",
       "\n",
       "                                                    rental_cost  time_blocks  \n",
       "trip_id                                                                       \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...            2            1  \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...            4            2  \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...            2            1  \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...            2            1  \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...            2            1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For rental cost, we can use an anonymous function to establish how many 30-minute blocks were used up by the rider in each trip (we round up the result with math.ceil() since a fraction of a block counts as an entire block):\n",
    "\n",
    "\n",
    "df['time_blocks'] = df[\"duration_min\"].apply(lambda x: math.ceil(x/30))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first 30 minutes are free, so we subtract 1 from this column:\n",
    "df['time_blocks'] = df['time_blocks'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rental_id</th>\n",
       "      <th>rental_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101368080</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101368081</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101368082</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101368083</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101368084</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>101628051</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>101628075</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>101628123</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>101628158</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>101628215</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rental_id  rental_cost\n",
       "0     101368080            2\n",
       "1     101368081            2\n",
       "2     101368082            2\n",
       "3     101368083            2\n",
       "4     101368084            2\n",
       "...         ...          ...\n",
       "9995  101628051            2\n",
       "9996  101628075            2\n",
       "9997  101628123            2\n",
       "9998  101628158            2\n",
       "9999  101628215            2\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Then we calculcate the rental costs. Here, we:\n",
    "#Count how many non-free time blocks there were for each rental_id using .groupby() (across all the trips related to that rental)\n",
    "#Multiply the number of blocks by Â£2\n",
    "#Add the Â£2 that the user had to pay upfront\n",
    "\n",
    "\n",
    "rental_cost = df.groupby(\"rental_id\")[\"time_blocks\"].sum().reset_index()\n",
    "rental_cost[\"rental_cost\"] = 2 + (rental_cost[\"time_blocks\"]*2)\n",
    "rental_cost = rental_cost.drop(columns=[\"time_blocks\"])\n",
    "rental_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "3_min"
    ]
   },
   "source": [
    "### Joining the `rental_cost` data (optional)\n",
    "\n",
    "Now, we can merge the two DataFrames and make `trip_id` the index. We can do this using the `.set_index()` DataFrame method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rental_id</th>\n",
       "      <th>bike_id</th>\n",
       "      <th>end_date</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>tag</th>\n",
       "      <th>user_category</th>\n",
       "      <th>duration_min</th>\n",
       "      <th>start_latitude</th>\n",
       "      <th>start_longitude</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_location</th>\n",
       "      <th>end_latitude</th>\n",
       "      <th>end_longitude</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_location</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>start_weekday</th>\n",
       "      <th>rental_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjMyOjAwOjEyODI5LjA=</th>\n",
       "      <td>101428476</td>\n",
       "      <td>12829.0</td>\n",
       "      <td>2020-03-09 20:32:00</td>\n",
       "      <td>132.0</td>\n",
       "      <td>2020-03-09 20:04:00</td>\n",
       "      <td>574</td>\n",
       "      <td>medium</td>\n",
       "      <td>A</td>\n",
       "      <td>28.0</td>\n",
       "      <td>51.533560</td>\n",
       "      <td>-0.093150</td>\n",
       "      <td>Eagle Wharf Road</td>\n",
       "      <td>Hoxton</td>\n",
       "      <td>51.523648</td>\n",
       "      <td>-0.074754</td>\n",
       "      <td>Bethnal Green Road</td>\n",
       "      <td>Shoreditch</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU2OjAwOjEwODYzLjA=</th>\n",
       "      <td>101522714</td>\n",
       "      <td>10863.0</td>\n",
       "      <td>2020-06-09 12:56:00</td>\n",
       "      <td>702.0</td>\n",
       "      <td>2020-06-09 12:11:00</td>\n",
       "      <td>82</td>\n",
       "      <td>medium</td>\n",
       "      <td>B</td>\n",
       "      <td>45.0</td>\n",
       "      <td>51.514274</td>\n",
       "      <td>-0.111257</td>\n",
       "      <td>Chancery Lane</td>\n",
       "      <td>Holborn</td>\n",
       "      <td>51.528681</td>\n",
       "      <td>-0.065550</td>\n",
       "      <td>Durant Street</td>\n",
       "      <td>Bethnal Green</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU2OjAwOjM5OTcuMA==</th>\n",
       "      <td>101377356</td>\n",
       "      <td>3997.0</td>\n",
       "      <td>2020-02-09 10:56:00</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2020-02-09 10:49:00</td>\n",
       "      <td>225</td>\n",
       "      <td>medium</td>\n",
       "      <td>A</td>\n",
       "      <td>7.0</td>\n",
       "      <td>51.509353</td>\n",
       "      <td>-0.196422</td>\n",
       "      <td>Notting Hill Gate Station</td>\n",
       "      <td>Notting Hill</td>\n",
       "      <td>51.497924</td>\n",
       "      <td>-0.183834</td>\n",
       "      <td>Gloucester Road (North)</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQwOjAwOjE2NTQyLjA=</th>\n",
       "      <td>101393663</td>\n",
       "      <td>16542.0</td>\n",
       "      <td>2020-02-09 18:40:00</td>\n",
       "      <td>622.0</td>\n",
       "      <td>2020-02-09 18:29:00</td>\n",
       "      <td>97</td>\n",
       "      <td>medium</td>\n",
       "      <td>A</td>\n",
       "      <td>11.0</td>\n",
       "      <td>51.497924</td>\n",
       "      <td>-0.183834</td>\n",
       "      <td>Gloucester Road (North)</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>51.507481</td>\n",
       "      <td>-0.205535</td>\n",
       "      <td>Lansdowne Road</td>\n",
       "      <td>Ladbroke Grove</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU3OjAwOjE2MDUuMA==</th>\n",
       "      <td>101622659</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>2020-08-09 19:57:00</td>\n",
       "      <td>219.0</td>\n",
       "      <td>2020-08-09 19:46:00</td>\n",
       "      <td>36</td>\n",
       "      <td>medium</td>\n",
       "      <td>A</td>\n",
       "      <td>11.0</td>\n",
       "      <td>51.501737</td>\n",
       "      <td>-0.184980</td>\n",
       "      <td>De Vere Gardens</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>51.490163</td>\n",
       "      <td>-0.190393</td>\n",
       "      <td>Bramham Gardens</td>\n",
       "      <td>Earl's Court</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    rental_id  bike_id  \\\n",
       "trip_id                                                                  \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...  101428476  12829.0   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...  101522714  10863.0   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...  101377356   3997.0   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...  101393663  16542.0   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...  101622659   1605.0   \n",
       "\n",
       "                                                               end_date  \\\n",
       "trip_id                                                                   \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...  2020-03-09 20:32:00   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...  2020-06-09 12:56:00   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...  2020-02-09 10:56:00   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...  2020-02-09 18:40:00   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...  2020-08-09 19:57:00   \n",
       "\n",
       "                                                   end_station_id  \\\n",
       "trip_id                                                             \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...          132.0   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...          702.0   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...           97.0   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...          622.0   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...          219.0   \n",
       "\n",
       "                                                            start_date  \\\n",
       "trip_id                                                                  \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM... 2020-03-09 20:04:00   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU... 2020-06-09 12:11:00   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU... 2020-02-09 10:49:00   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ... 2020-02-09 18:29:00   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU... 2020-08-09 19:46:00   \n",
       "\n",
       "                                                    start_station_id     tag  \\\n",
       "trip_id                                                                        \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...               574  medium   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...                82  medium   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...               225  medium   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...                97  medium   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...                36  medium   \n",
       "\n",
       "                                                   user_category  \\\n",
       "trip_id                                                            \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...             A   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...             B   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...             A   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...             A   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...             A   \n",
       "\n",
       "                                                    duration_min  \\\n",
       "trip_id                                                            \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...          28.0   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...          45.0   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...           7.0   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...          11.0   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...          11.0   \n",
       "\n",
       "                                                    start_latitude  \\\n",
       "trip_id                                                              \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...       51.533560   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...       51.514274   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...       51.509353   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...       51.497924   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...       51.501737   \n",
       "\n",
       "                                                    start_longitude  \\\n",
       "trip_id                                                               \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...        -0.093150   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...        -0.111257   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...        -0.196422   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...        -0.183834   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...        -0.184980   \n",
       "\n",
       "                                                           start_station_name  \\\n",
       "trip_id                                                                         \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...           Eagle Wharf Road   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...              Chancery Lane   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...  Notting Hill Gate Station   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...    Gloucester Road (North)   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...            De Vere Gardens   \n",
       "\n",
       "                                                   start_location  \\\n",
       "trip_id                                                             \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...         Hoxton   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...        Holborn   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...   Notting Hill   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...     Kensington   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...     Kensington   \n",
       "\n",
       "                                                    end_latitude  \\\n",
       "trip_id                                                            \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...     51.523648   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...     51.528681   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...     51.497924   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...     51.507481   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...     51.490163   \n",
       "\n",
       "                                                    end_longitude  \\\n",
       "trip_id                                                             \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...      -0.074754   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...      -0.065550   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...      -0.183834   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...      -0.205535   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...      -0.190393   \n",
       "\n",
       "                                                           end_station_name  \\\n",
       "trip_id                                                                       \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...       Bethnal Green Road   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...            Durant Street   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...  Gloucester Road (North)   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...           Lansdowne Road   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...          Bramham Gardens   \n",
       "\n",
       "                                                      end_location  \\\n",
       "trip_id                                                              \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...      Shoreditch   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...   Bethnal Green   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...      Kensington   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...  Ladbroke Grove   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...    Earl's Court   \n",
       "\n",
       "                                                    start_hour  start_weekday  \\\n",
       "trip_id                                                                         \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...          20              0   \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...          12              1   \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...          10              6   \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...          18              6   \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...          19              6   \n",
       "\n",
       "                                                    rental_cost  \n",
       "trip_id                                                          \n",
       "MjAyMC0wMy0wOSAyMDowNDowMDoyMDIwLTAzLTA5IDIwOjM...            2  \n",
       "MjAyMC0wNi0wOSAxMjoxMTowMDoyMDIwLTA2LTA5IDEyOjU...            4  \n",
       "MjAyMC0wMi0wOSAxMDo0OTowMDoyMDIwLTAyLTA5IDEwOjU...            2  \n",
       "MjAyMC0wMi0wOSAxODoyOTowMDoyMDIwLTAyLTA5IDE4OjQ...            2  \n",
       "MjAyMC0wOC0wOSAxOTo0NjowMDoyMDIwLTA4LTA5IDE5OjU...            2  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We've generated the rental_cost DataFrame for you, but you will have to figure out the code we used (in Exercise 6)!\n",
    "rental_cost = pd.read_csv(\"data/rental_cost.csv\")\n",
    "\n",
    "df = pd.merge(df, rental_cost, left_on=\"rental_id\", right_on=\"rental_id\", how=\"left\")\n",
    "df = df.set_index(\"trip_id\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "2_min"
    ]
   },
   "source": [
    "## Exporting the dataset\n",
    "\n",
    "Our dataset is now clean and ready to be exported and delivered to our client. We save it to our working directory using the [**`.to_csv()`**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html) method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"clean.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method can take many arguments (check the [docs](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html) for details). Here we only used the desired filename (`\"clean.csv\"`) and `encoding=\"utf-8\"`, to make sure the result uses UTF-8 (this is the default value, so we could have also left this argument unspecified). If we wanted our file to be saved to a subfolder (say, `results/`), we could run `df.to_csv(\"results/clean.csv\", encoding=\"utf-8\")` instead."
   ]
  }
 ],
 "metadata": {
  "c1_recart": "6.4.0-57c20131aabc1dc2a8c675852d80a7da",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
